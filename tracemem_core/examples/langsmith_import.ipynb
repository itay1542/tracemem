{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Import LangSmith Traces into TraceMem\n",
    "\n",
    "This notebook fetches conversation traces from LangSmith and imports them\n",
    "into TraceMem's knowledge graph for retrieval, then uses retrieved memories\n",
    "as context for an LLM call.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Neo4j running locally (`docker compose up -d neo4j`)\n",
    "- `LANGSMITH_API_KEY` in `.env`\n",
    "- `OPENAI_API_KEY` in `.env` (for embeddings and LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-heading",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. LanceDB at: /var/folders/lf/j9dpx4lx3bl0x2tgdkr0pn8c0000gn/T/tracemem_langsmith_3pl_fddx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langsmith import Client\n",
    "\n",
    "from tracemem_core import RetrievalConfig, TraceMem, TraceMemConfig\n",
    "from tracemem_core.messages import Message, ToolCall\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class TradingResourceExtractor:\n",
    "    \"\"\"Resource extractor for trading agent tools.\"\"\"\n",
    "\n",
    "    def extract(self, tool_name: str, args: dict[str, Any]) -> str | None:\n",
    "        if tool_name == \"get_ticker_details\":\n",
    "            symbol = args.get(\"symbol\")\n",
    "            if symbol and isinstance(symbol, str):\n",
    "                return f\"ticker://{symbol.upper()}\"\n",
    "        return None\n",
    "\n",
    "\n",
    "ls_client = Client()\n",
    "\n",
    "_tmpdir = tempfile.mkdtemp(prefix=\"tracemem_langsmith_\")\n",
    "config = TraceMemConfig(\n",
    "    mode=\"global\",\n",
    "    lancedb_path=Path(_tmpdir) / \"lancedb\",\n",
    ")\n",
    "\n",
    "tm = TraceMem(config=config, resource_extractor=TradingResourceExtractor())\n",
    "await tm.__aenter__()\n",
    "\n",
    "print(f\"Connected. LanceDB at: {_tmpdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fetch-heading",
   "metadata": {},
   "source": [
    "## 2. Fetch Traces from LangSmith\n",
    "\n",
    "Get all root traces for a specific user from the `stonki_prd` project,\n",
    "grouped by `thread_id` (conversation thread)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fetch-traces",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 100 root traces\n",
      "Across 21 threads\n",
      "  dd7097a2-970... (8 turns) - ðŸ”” **Trigger Alert**\n",
      "\n",
      "message: Review all portfolio positions, check P&L changes,\n",
      "  5bb94f2d-246... (37 turns) - analyze SKYT using SEPA criteria (mark mineervini) which phase is it in and wher\n",
      "  dd27c455-e98... (17 turns) - ðŸ”” **Trigger Alert**\n",
      "\n",
      "message: Perform daily portfolio review: Check all current \n",
      "  59ba5197-fc5... (2 turns) - ðŸ”” **Trigger Alert**\n",
      "\n",
      "message: Review CVNA ultra-deep OTM position: 10 contracts \n",
      "  291c97d7-8c7... (1 turns) - Hi\n",
      "  90819e3a-5b7... (1 turns) - I closed my short put at 50% profit and the stock has gone up even more. Can you\n",
      "  1ac1ebd7-df2... (1 turns) - how come qcom is lagging behind the ai chip frenzy?\n",
      "  e8bc2ed5-33d... (1 turns) - Analyze WOLF and especially the option activity\n",
      "  b4dbc6d3-a68... (5 turns) - Create a recipe to track these stocks:\n",
      "  4a0af4a5-4c3... (1 turns) - Analyze nxxt for a swing trade\n",
      "  b644f647-75a... (1 turns) - what are people saying about RIME on reddit\n",
      "  f26d8fad-1f3... (10 turns) - whats the deal with OMER it has a very interesting graph with gaps ? analyze pas\n",
      "  c02c6d63-205... (1 turns) - hi\n",
      "  8599bf57-3a2... (1 turns) - can you check QQQ price?\n",
      "  8c08714b-8d3... (1 turns) - can you please schedule a scheduled reminder to check qqq price every 5m\n",
      "  b74ae644-3f5... (1 turns) - can you check latest tesla action\n",
      "  f7943f09-9ed... (1 turns) - can you check tesla latest action like news\n",
      "  7aa09c2c-593... (1 turns) - can you check Tesla latest action like price action technical news options every\n",
      "  82e5600a-3b1... (1 turns) - can you check Tesla latest action like price action technical news options every\n",
      "  249e2096-4dd... (2 turns) - what does AXTI do? research this company\n",
      "  e56ebdaa-1c4... (6 turns) - ASST bitcoin holdings are worth more than its market cap how come?\n"
     ]
    }
   ],
   "source": [
    "PROJECT = \"stonki_prd\"\n",
    "USER_ID = \"user_33nESbTFBKeYhcXBFV2S9Mx193o\"\n",
    "\n",
    "root_traces = list(ls_client.list_runs(\n",
    "    project_name=PROJECT,\n",
    "    is_root=True,\n",
    "    filter=f'has(metadata, \\'{{\"user_id\": \"{USER_ID}\"}}\\') ',\n",
    "    limit=100,\n",
    "))\n",
    "\n",
    "print(f\"Fetched {len(root_traces)} root traces\")\n",
    "\n",
    "# Group by thread_id\n",
    "threads: dict[str, list] = {}\n",
    "for t in root_traces:\n",
    "    tid = (t.metadata or {}).get(\"thread_id\", \"unknown\")\n",
    "    threads.setdefault(tid, []).append(t)\n",
    "\n",
    "# Sort each thread chronologically\n",
    "for tid in threads:\n",
    "    threads[tid].sort(key=lambda r: r.start_time)\n",
    "\n",
    "print(f\"Across {len(threads)} threads\")\n",
    "for tid, runs in sorted(threads.items(), key=lambda x: x[1][0].start_time):\n",
    "    first_msg = (runs[0].inputs or {}).get(\"messages\", [{}])\n",
    "    first_content = first_msg[0].get(\"content\", \"\")[:80] if first_msg else \"\"\n",
    "    print(f\"  {tid[:12]}... ({len(runs)} turns) - {first_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convert-heading",
   "metadata": {},
   "source": [
    "## 3. Convert LangSmith Traces to TraceMem Messages\n",
    "\n",
    "LangSmith root trace outputs contain the full conversation as a list of\n",
    "messages with `type` field (`human`, `ai`, `tool`). AI messages may have\n",
    "content blocks (thinking, text, tool_use) and tool_calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "converter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread e56ebdaa-1c4... last trace has 38 raw msgs -> 38 TraceMem msgs\n",
      "  [user     ] ASST bitcoin holdings are worth more than its market cap how come?\n",
      "  [assistant]  tool_calls=['get_ticker_details']\n",
      "  [tool     ] {\n",
      "  \"active\": true,\n",
      "  \"address\": {\n",
      "    \"address1\": \"100 CRESCENT CT\",\n",
      "    \"addre\n",
      "  [assistant] Good catchâ€”that's actually a classic Bitcoin treasury company arbitrage situatio\n",
      "  [user     ] use web search\n",
      "  [assistant]  tool_calls=['transfer_to_websearch_agent']\n",
      "  ... (32 more)\n"
     ]
    }
   ],
   "source": [
    "def extract_text_content(content) -> str:\n",
    "    \"\"\"Extract text from LangSmith message content (string or block list).\"\"\"\n",
    "    if isinstance(content, str):\n",
    "        return content\n",
    "    if isinstance(content, list):\n",
    "        texts = []\n",
    "        for block in content:\n",
    "            if isinstance(block, dict) and block.get(\"type\") == \"text\":\n",
    "                texts.append(block.get(\"text\", \"\"))\n",
    "        return \"\\n\".join(texts)\n",
    "    return str(content) if content else \"\"\n",
    "\n",
    "\n",
    "def extract_tool_calls(msg: dict) -> list[ToolCall]:\n",
    "    \"\"\"Extract tool calls from a LangSmith AI message.\"\"\"\n",
    "    tool_calls = []\n",
    "    # tool_calls field (LangChain format)\n",
    "    for tc in msg.get(\"tool_calls\", []):\n",
    "        tool_calls.append(ToolCall(\n",
    "            id=tc.get(\"id\", \"\"),\n",
    "            name=tc.get(\"name\", \"\"),\n",
    "            args=tc.get(\"args\", {}),\n",
    "        ))\n",
    "    # Also check content blocks for tool_use\n",
    "    content = msg.get(\"content\", \"\")\n",
    "    if isinstance(content, list):\n",
    "        for block in content:\n",
    "            if isinstance(block, dict) and block.get(\"type\") == \"tool_use\":\n",
    "                tc_id = block.get(\"id\", \"\")\n",
    "                # Skip if already captured from tool_calls field\n",
    "                if not any(t.id == tc_id for t in tool_calls):\n",
    "                    tool_calls.append(ToolCall(\n",
    "                        id=tc_id,\n",
    "                        name=block.get(\"name\", \"\"),\n",
    "                        args=block.get(\"input\", {}),\n",
    "                    ))\n",
    "    return tool_calls\n",
    "\n",
    "\n",
    "def langsmith_messages_to_tracemem(messages: list[dict]) -> list[Message]:\n",
    "    \"\"\"Convert LangSmith output messages to TraceMem Messages.\"\"\"\n",
    "    result = []\n",
    "    for msg in messages:\n",
    "        msg_type = msg.get(\"type\", \"\")\n",
    "        content = extract_text_content(msg.get(\"content\", \"\"))\n",
    "\n",
    "        if msg_type == \"human\":\n",
    "            # Skip system reminders injected as human messages\n",
    "            if content.startswith(\"<system_reminder>\"):\n",
    "                continue\n",
    "            result.append(Message(role=\"user\", content=content))\n",
    "\n",
    "        elif msg_type == \"ai\":\n",
    "            tool_calls = extract_tool_calls(msg)\n",
    "            result.append(Message(\n",
    "                role=\"assistant\",\n",
    "                content=content,\n",
    "                tool_calls=tool_calls,\n",
    "            ))\n",
    "\n",
    "        elif msg_type == \"tool\":\n",
    "            tool_content = msg.get(\"content\", \"\")\n",
    "            if isinstance(tool_content, (dict, list)):\n",
    "                tool_content = json.dumps(tool_content)[:2000]\n",
    "            result.append(Message(\n",
    "                role=\"tool\",\n",
    "                content=str(tool_content)[:2000],\n",
    "                tool_call_id=msg.get(\"tool_call_id\", \"\"),\n",
    "            ))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Test with one trace\n",
    "sample_thread_id = list(threads.keys())[0]\n",
    "sample_runs = threads[sample_thread_id]\n",
    "last_run = sample_runs[-1]\n",
    "out_msgs = (last_run.outputs or {}).get(\"messages\", [])\n",
    "\n",
    "converted = langsmith_messages_to_tracemem(out_msgs)\n",
    "print(f\"Thread {sample_thread_id[:12]}... last trace has {len(out_msgs)} raw msgs -> {len(converted)} TraceMem msgs\")\n",
    "for m in converted[:6]:\n",
    "    tc_str = f\" tool_calls={[t.name for t in m.tool_calls]}\" if m.tool_calls else \"\"\n",
    "    print(f\"  [{m.role:9s}] {m.content[:80]}{tc_str}\")\n",
    "if len(converted) > 6:\n",
    "    print(f\"  ... ({len(converted) - 6} more)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-heading",
   "metadata": {},
   "source": [
    "## 4. Import All Threads into TraceMem\n",
    "\n",
    "For each thread, we take the **last trace's output messages** (which\n",
    "contains the full conversation history) and import it as a single\n",
    "conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "import-all",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dd7097a2-970... 5 user + 8 assistant msgs -> 2 nodes\n",
      "  5bb94f2d-246... 8 user + 19 assistant msgs -> 2 nodes\n",
      "  dd27c455-e98... 7 user + 18 assistant msgs -> 2 nodes\n",
      "  59ba5197-fc5... 2 user + 2 assistant msgs -> 2 nodes\n",
      "  291c97d7-8c7... 1 user + 1 assistant msgs -> 2 nodes\n",
      "  90819e3a-5b7... 5 user + 19 assistant msgs -> 4 nodes\n",
      "  1ac1ebd7-df2... 1 user + 5 assistant msgs -> 2 nodes\n",
      "  e8bc2ed5-33d... 1 user + 9 assistant msgs -> 4 nodes\n",
      "  b4dbc6d3-a68... 5 user + 12 assistant msgs -> 2 nodes\n",
      "  4a0af4a5-4c3... 1 user + 5 assistant msgs -> 4 nodes\n",
      "  b644f647-75a... 1 user + 4 assistant msgs -> 2 nodes\n",
      "  f26d8fad-1f3... 10 user + 36 assistant msgs -> 2 nodes\n",
      "  c02c6d63-205... 1 user + 1 assistant msgs -> 2 nodes\n",
      "  8599bf57-3a2... 1 user + 2 assistant msgs -> 2 nodes\n",
      "  8c08714b-8d3... 1 user + 1 assistant msgs -> 2 nodes\n",
      "  b74ae644-3f5... 1 user + 2 assistant msgs -> 2 nodes\n",
      "  f7943f09-9ed... 1 user + 4 assistant msgs -> 2 nodes\n",
      "  7aa09c2c-593... 1 user + 11 assistant msgs -> 2 nodes\n",
      "  82e5600a-3b1... 1 user + 6 assistant msgs -> 2 nodes\n",
      "  249e2096-4dd... 2 user + 6 assistant msgs -> 4 nodes\n",
      "  e56ebdaa-1c4... 6 user + 20 assistant msgs -> 4 nodes\n",
      "\n",
      "Imported 21 threads\n"
     ]
    }
   ],
   "source": [
    "imported = {}\n",
    "\n",
    "for thread_id, runs in sorted(threads.items(), key=lambda x: x[1][0].start_time):\n",
    "    # Use the last trace's output â€” it has the full conversation\n",
    "    last_run = runs[-1]\n",
    "    out_msgs = (last_run.outputs or {}).get(\"messages\", [])\n",
    "\n",
    "    if not out_msgs:\n",
    "        print(f\"  SKIP {thread_id[:12]}... (no output messages)\")\n",
    "        continue\n",
    "\n",
    "    messages = langsmith_messages_to_tracemem(out_msgs)\n",
    "    if not messages:\n",
    "        print(f\"  SKIP {thread_id[:12]}... (no convertible messages)\")\n",
    "        continue\n",
    "\n",
    "    result = await tm.import_trace(thread_id, messages)\n",
    "    user_count = sum(1 for m in messages if m.role == \"user\")\n",
    "    assistant_count = sum(1 for m in messages if m.role == \"assistant\")\n",
    "    imported[thread_id] = result\n",
    "    print(f\"  {thread_id[:12]}... {user_count} user + {assistant_count} assistant msgs -> {len(result)} nodes\")\n",
    "\n",
    "print(f\"\\nImported {len(imported)} threads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "search-heading",
   "metadata": {},
   "source": [
    "## 5. Search Imported Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(f95f63bd, score=0.033, conv=e56ebdaa-1c4b-4679-905d-27e663c7e09c, text='ASST bitcoin holdings are worth more than its market cap how...', context=yes)\n",
      "\n",
      "Result(2f761ddf, score=0.032, conv=e56ebdaa-1c4b-4679-905d-27e663c7e09c, text='current market cap is 738M can you check recent news that sa...', context=yes)\n",
      "\n",
      "Result(2626394f, score=0.031, conv=e56ebdaa-1c4b-4679-905d-27e663c7e09c, text='can you compare to MSTR and other bitcoin treasuries', context=yes)\n",
      "\n",
      "Result(0d60b4bc, score=0.031, conv=b4dbc6d3-a680-4956-8b42-eb34de76a60e, text='Document my thesis on each stock. Wolf 250 dte moonshot call...', context=yes)\n",
      "\n",
      "Result(23993b57, score=0.030, conv=dd27c455-e988-435b-b1a8-18a394eac8c9, text='**[Summary of conversation which got stale or too long]**\\n\\nT...', context=yes)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = await tm.search(\"bitcoin holdings market cap\", config=RetrievalConfig(limit=5))\n",
    "\n",
    "for r in results:\n",
    "    print(r)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trajectory-heading",
   "metadata": {},
   "source": [
    "## 6. Expand a Result to Full Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "trajectory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory(4 steps):\n",
      "  Step(f95f63bd UserText: 'ASST bitcoin holdings are worth more than its market cap how...')\n",
      "  Step(0d98dcf4 AgentText: '' tools=[get_ticker_details])\n",
      "  Step(46979700 AgentText: \"Good catchâ€”that's actually a classic Bitcoin treasury compan...\")\n",
      "  Step(04abc4d1 UserText: 'use web search')\n"
     ]
    }
   ],
   "source": [
    "if results:\n",
    "    trajectory = await tm.get_trajectory(results[0].node_id)\n",
    "    print(trajectory)\n",
    "else:\n",
    "    print(\"No results to expand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "search2-heading",
   "metadata": {},
   "source": [
    "## 7. LLM Call with Retrieved Memories\n",
    "\n",
    "Use TraceMem to retrieve relevant past conversations, then pass them as\n",
    "context to an LLM call via the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "search2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved context:\n",
      "\n",
      "Memory 1 (score=0.031, conversation=e56ebdaa-1c4...):\n",
      "  User: ASST bitcoin holdings are worth more than its market cap how come?\n",
      "  Agent: \n",
      "  Tools used: GET_TICKER_DETAILS(ticker://ASST rv=950caab2 res=62514a0b)\n",
      "\n",
      "Memory 2 (score=0.031, conversation=b4dbc6d3-a68...):\n",
      "  User: Document my thesis on each stock. Wolf 250 dte moonshot calls 35 strike, high risk high reward if they navigate their financial situation correctly. Axti double top and currently holding gap , high volatility small mcap but very important for chip industry (search for reddit posts on this). Skyt a us based foundry as a service still small 1.5B cap could 10x from here but a bit over bought. Deploy 5K over 2 weeks. Finally qcom severly behind ai peers but can rally when ai moves to edge - accumulating leaps 200 strike\n",
      "  Agent: Let me search for Reddit discussion on AXTI to add context to your thesis, then I'll create the recipe documenting your positions.\n",
      "\n",
      "Memory 3 (score=0.031, conversation=e56ebdaa-1c4...):\n",
      "  User: can you compare to MSTR and other bitcoin treasuries\n",
      "  Agent: \n",
      "\n",
      "Memory 4 (score=0.030, conversation=dd27c455-e98...):\n",
      "  User: **[Summary of conversation which got stale or too long]**\n",
      "\n",
      "The user initiated a daily portfolio review. The assistant performed a comprehensive check of current holdings and option positions using `get_holdings`, `get_most_recent_bar`, and `get_option_positions`.\n",
      "\n",
      "**Key topics and symbols discussed:**\n",
      "The review focused on the user's portfolio, with particular attention to **NFE** (long position) and **IBIT** (short position and straddle). Other symbols reviewed include AAPL, DFTX, IBM, IREN, MNST, MOH, NET, VST, WMT, APLD, ASST, CVNA, QCOM, RXRX, SMLR, and WDC.\n",
      "\n",
      "**Assistant's insights and recommendations:**\n",
      "The assistant identified a critical development with **NFE**, which had a major breakout, rallying significantly to $1.775 (a +46% gain from the user's average entry of $1.21). This surpassed the previous $1.50 take-profit target. The assistant emphasized the urgency of a profit-taking decision for NFE and proposed three options:\n",
      "*   **Option A (Conservative):** Sell 50% (1,950 shares) at market open.\n",
      "*   **Option B (Aggressive):** Trail with a $1.60 stop, targeting $2.00+.\n",
      "*   **Option C (Scale Out):** Sell 25% on Monday, 25% at $1.85, 25% at $2.00, and trail the final 25%.\n",
      "\n",
      "The assistant also highlighted the increasing risk of the **IBIT short position** due to Bitcoin's bullish momentum and the straddle expiring in 7 days. It recommended considering covering 50% (160 shares) of the short position on Monday morning to reduce exposure.\n",
      "\n",
      "The assistant also provided a breakdown of other positions:\n",
      "*   **Top Performers:** DFTX, MNST, MOH, WMT, and IREN were noted for strong momentum, with suggestions for trailing stops or partial profit-taking.\n",
      "*   **Underperformers:** NET, VST, and AAPL were identified as needing monitoring.\n",
      "*   **Earnings Risk:** IBM has earnings in 4 days, and the assistant suggested holding through or trimming the position.\n",
      "*   **Options Portfolio:** APLD Puts and IREN Calls were profitable, while QCOM Sep Calls, CVNA Puts, and ASST Calls showed mixed or underwater performance.\n",
      "\n",
      "**Ongoing context:**\n",
      "The assistant is awaiting the user's decision on the proposed actions for NFE and IBIT. The user needs to provide direction on the profit-taking strategy for NFE and risk management for the IBIT short. The assistant also advised monitoring Bitcoin price action over the weekend due to its impact on IBIT and IREN.\n",
      "\n",
      "**Update from Monday's review:**\n",
      "The assistant performed another daily portfolio review.\n",
      "*   **NFE** closed at $1.765, still showing a significant unrealized profit of +$2,155 (+46%). The assistant reiterated the need for a profit-taking decision and again recommended Option C (scaling out).\n",
      "*   **NET** experienced a significant rally of +11.1%, closing at $190.789, reducing its unrealized loss. The assistant suggested revalidating the thesis and holding/adding if it breaks above the entry price.\n",
      "*   The **IBIT short position** is back in profit (+ $1,178) due to Bitcoin's pullback. The assistant noted the risk has eased but advised keeping the $54 alert active.\n",
      "*   **IREN** corrected hard (-8%) due to Bitcoin weakness but remains profitable.\n",
      "*   **IBM** earnings are in 2 days (Wednesday). The assistant recommended trimming 50% of the position on Tuesday morning to lock in profit.\n",
      "*   The **IBIT straddle** expires in 4 days and is barely profitable (+$90). The assistant recommended closing the entire straddle on Tuesday to take the small profit and avoid further theta decay.\n",
      "\n",
      "**Immediate Action Plan for Tuesday:**\n",
      "The assistant recommended the following high-priority actions for Tuesday, January 27:\n",
      "1.  **NFE:** Make a profit-taking decision (recommended: scale out 25% at open, 25% at $1.85, 25% at $2.00, trail final 25%).\n",
      "2.  **IBM:** Sell 20 shares at market open to lock in profit before earnings.\n",
      "3.  **IBIT Straddle:** Close both legs for the net profit.\n",
      "\n",
      "The assistant also highlighted upcoming catalysts including the Fed Rate Decision on Tuesday and IBM earnings on Wednesday, and emphasized the importance of locking in gains.. Latest query preserved above this message.\n",
      "  Agent: IBM earnings alert firing - assessing position now. <tickers>IBM</tickers>\n",
      "\n",
      "Memory 5 (score=0.016, conversation=90819e3a-5b7...):\n",
      "  User: **[Summary of conversation]**\n",
      "\n",
      "The user initiated the conversation by asking for volatile, trendy, and liquid stocks (at least 5M average volume, high beta, trending) suitable for day trading, drawing from scanner data, Reddit, and general web sources.\n",
      "\n",
      "The assistant used the `scanner_agent` to identify top day trading candidates, categorizing them into Tier 1 (APLD, SMR, ACHR), Tier 2 (BBAI, LUNR, HUT, BITF), and Large Cap Options (COIN, SHOP). Key observations included strong momentum in crypto-related stocks, high volatility in space/defense plays, and high volume in AI/tech stocks.\n",
      "\n",
      "The `social_media_agent` provided an intelligence summary of trending topics on WallStreetBets and other trading subreddits. It highlighted themes like card issuers/BNPL (COF, AXP, C, JPM, AFRM), defense/AI infrastructure (IREN, APLD, ONDS), space (ASTS, RKLB), mortgage/housing (RKT), silver/miners (PAAS), and a China mega-cap (BABA). Sentiment analysis was provided for each theme, along with actionable bullish and bearish watchlists.\n",
      "\n",
      "The `websearch_agent` explained that it could not provide real-time recommendations for a future date (January 12, 2026, which was the date used in the initial prompt's context) but outlined the methods and tools day traders use to find such stocks (premarket scanners, high volume movers, catalysts, high beta, liquidity).\n",
      "\n",
      "The assistant then synthesized these findings, presenting a consolidated day trading watchlist with \"Cross-Validated Top Picks\" (APLD, IREN, ASTS, RKLB), \"Policy-Driven Volatility Plays\" (COF, AXP, C, JPM, AFRM), \"High Beta Scanner Standouts\" (SMR, ACHR, BBAI, HUT, BITF, COIN), and \"Contrarian/Metals Play\" (PAAS, RKT, BABA). It recommended APLD, the credit card group vs. AFRM, and BBAI as the best setups.\n",
      "\n",
      "The user then asked for \"afrm key levels\". The assistant used `get_most_recent_bar` and `get_technical_indicators` to gather current data for AFRM and then transferred to the `ta_agent` for a detailed technical analysis. The `ta_agent` provided comprehensive intraday resistance and support levels, previous day references, significant recent price zones, VWAP context, and intraday moving average analysis for AFRM, concluding with a trading takeaway for the day.\n",
      "\n",
      "The user stated they were \"in at 81.5\" for AFRM. The assistant provided immediate context for the trade, including risk levels, profit zones, and what to watch, and offered to create a tracking recipe or monitoring task.\n",
      "\n",
      "The user then reported being \"stopped out :(\". The assistant acknowledged the stop-out, performed a quick post-mortem, explaining the breakdown below VWAP and the potential for a headline reversal, and praised the user's risk management. It then asked if the user wanted to pivot to other watchlist names.\n",
      "\n",
      "The user commented \"its dumping\". The assistant used `get_most_recent_bar` to confirm AFRM's continued decline, noting it had collapsed through all support levels and was in \"free-fall mode,\" reinforcing the value of the user's early stop.\n",
      "\n",
      "The user then asked \"from this watchlist anything entry worth right now?\". The assistant used `get_most_recent_bar` for the entire watchlist and identified PAAS as the \"cleanest setup\" with positive momentum and holding VWAP. It also noted BABA as a strong but extended contrarian play and advised avoiding several other stocks that were fading or dumping. It recommended PAAS as the best risk/reward.\n",
      "\n",
      "The user asked to \"check again\". The assistant again used `get_most_recent_bar` for the watchlist. It then updated its recommendation, identifying IREN as the \"best setup right now\" due to its breakout above VWAP with accelerating volume, while PAAS had cooled slightly.\n",
      "\n",
      "The user then stated \"got in iren at 48.9, stop?\". The assistant provided immediate context for the IREN trade, noting the entry was a bit of a chase, and recommended a tight stop at $48.00, explaining the rationale and potential targets.\n",
      "\n",
      "The user repeatedly asked \"check now\" and \"now?\". The assistant used `get_most_recent_bar` for IREN, confirming a significant price surge. It informed the user they were in profit and advised considering scaling out, moving the stop to breakeven, and provided remaining runner targets.\n",
      "\n",
      "Finally, the user stated \"my tp was 7 cents above a spike and now im red\". The assistant used `get_most_recent_bar` for IREN, confirmed the whipsaw, and noted the price had reversed below the user's entry and VWAP. It recommended cutting the trade for a scratch/small loss, highlighting the rapid reversals in momentum plays.\n",
      "\n",
      "The ongoing context is that the user is actively day trading and seeking real-time analysis and recommendations for volatile stocks, with a focus on entry, stop-loss, and profit-taking levels. The assistant is providing dynamic updates and risk management advice.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "LLM Response:\n",
      "\n",
      "From our past conversations, I know that you have a short position in IBIT, which is sensitive to Bitcoin price movements, and you've been monitoring Bitcoin's bullish momentum closely. You also mentioned comparing ASST to other Bitcoin-related treasuries, like MSTR. Additionally, during portfolio reviews, I've provided insights and risk management strategies concerning your crypto-related positions, especially in light of Bitcoin's price action. If you have specific questions or need more detailed insights, please let me know!\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "USER_QUERY = \"What do you know about my bitcoin and crypto holdings?\"\n",
    "\n",
    "# Retrieve relevant memories\n",
    "memories = await tm.search(USER_QUERY, config=RetrievalConfig(limit=5))\n",
    "\n",
    "# Build context from retrieved memories\n",
    "context_parts = []\n",
    "for i, mem in enumerate(memories, 1):\n",
    "    part = f\"Memory {i} (score={mem.score:.3f}, conversation={mem.conversation_id[:12]}...):\\n\"\n",
    "    part += f\"  User: {mem.text}\\n\"\n",
    "    if mem.context and mem.context.agent_text:\n",
    "        part += f\"  Agent: {mem.context.agent_text.text[:500]}\\n\"\n",
    "    if mem.context and mem.context.tool_uses:\n",
    "        tools = \", \".join(str(t) for t in mem.context.tool_uses)\n",
    "        part += f\"  Tools used: {tools}\\n\"\n",
    "    context_parts.append(part)\n",
    "\n",
    "context_block = \"\\n\".join(context_parts)\n",
    "print(\"Retrieved context:\\n\")\n",
    "print(context_block)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "# LLM call with memories as context\n",
    "client = openai.OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a helpful assistant. Use the following memories from past \"\n",
    "                \"conversations to provide an informed answer. If the memories don't \"\n",
    "                \"contain relevant information, say so.\\n\\n\"\n",
    "                f\"## Past Conversation Memories\\n\\n{context_block}\"\n",
    "            ),\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": USER_QUERY},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"LLM Response:\\n\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-heading",
   "metadata": {},
   "source": [
    "## 8. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cleanup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "await tm.__aexit__(None, None, None)\n",
    "shutil.rmtree(_tmpdir, ignore_errors=True)\n",
    "print(\"Cleaned up\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
