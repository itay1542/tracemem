{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# TraceMem + LangChain Example\n",
    "\n",
    "This notebook demonstrates importing LangChain conversation traces into TraceMem\n",
    "and querying them using the retrieval API.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Neo4j running locally (`docker compose up -d neo4j`)\n",
    "- `langchain-core` installed (`uv add langchain-core`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-heading",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Create a mock embedder (no OpenAI key needed), configure TraceMem with\n",
    "a temp LanceDB path to avoid conflicts with existing data, and connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. LanceDB at: /var/folders/lf/j9dpx4lx3bl0x2tgdkr0pn8c0000gn/T/tracemem_example_pni8ts5k\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "from tracemem_core import TraceMem, TraceMemConfig, RetrievalConfig, Embedder\n",
    "from tracemem_core.adapters.langchain import LangChainAdapter\n",
    "\n",
    "\n",
    "class MockEmbedder(Embedder):\n",
    "    \"\"\"Deterministic embedder for demo purposes (no API key needed).\"\"\"\n",
    "\n",
    "    @property\n",
    "    def dimensions(self) -> int:\n",
    "        return 256\n",
    "\n",
    "    async def embed(self, text: str) -> list[float]:\n",
    "        rng = random.Random(text)\n",
    "        vec = [rng.gauss(0, 1) for _ in range(self.dimensions)]\n",
    "        norm = sum(x * x for x in vec) ** 0.5\n",
    "        return [x / norm for x in vec]\n",
    "\n",
    "    async def embed_batch(self, texts: list[str]) -> list[list[float]]:\n",
    "        return [await self.embed(t) for t in texts]\n",
    "\n",
    "\n",
    "# Use a temp directory for LanceDB so we don't conflict with existing data\n",
    "_tmpdir = tempfile.mkdtemp(prefix=\"tracemem_example_\")\n",
    "\n",
    "config = TraceMemConfig(\n",
    "    mode=\"global\",\n",
    "    embedding_dimensions=256,\n",
    "    lancedb_path=Path(_tmpdir) / \"lancedb\",\n",
    "    reranker=\"rrf\",\n",
    "    retrieval=RetrievalConfig(limit=5, include_context=True),\n",
    ")\n",
    "\n",
    "adapter = LangChainAdapter()\n",
    "embedder = MockEmbedder()\n",
    "\n",
    "# Open a single TraceMem connection for the whole notebook\n",
    "tm = TraceMem(config=config, embedder=embedder)\n",
    "await tm.__aenter__()\n",
    "\n",
    "print(f\"Connected. LanceDB at: {_tmpdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-heading",
   "metadata": {},
   "source": [
    "## 2. Import a LangChain Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "import-trace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported nodes: ['user_text', 'agent_text', 'resource_file:///src/auth.py', 'resource_version_file:///src/auth.py']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "langchain_messages = [\n",
    "    HumanMessage(content=\"Read the auth.py file and explain the login flow\"),\n",
    "    AIMessage(\n",
    "        content=\"I'll read the file for you.\",\n",
    "        tool_calls=[\n",
    "            {\"id\": \"call_1\", \"name\": \"read_file\", \"args\": {\"file_path\": \"/src/auth.py\"}}\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\n",
    "        content=\"def login(user, password):\\n    token = create_jwt(user)\\n    return token\",\n",
    "        tool_call_id=\"call_1\",\n",
    "    ),\n",
    "    AIMessage(content=\"The login flow creates a JWT token from the user credentials and returns it.\"),\n",
    "    HumanMessage(content=\"Now add rate limiting to the login endpoint\"),\n",
    "    AIMessage(\n",
    "        content=\"I'll update auth.py to add rate limiting.\",\n",
    "        tool_calls=[\n",
    "            {\"id\": \"call_2\", \"name\": \"edit_file\", \"args\": {\"file_path\": \"/src/auth.py\"}}\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(content=\"File updated successfully\", tool_call_id=\"call_2\"),\n",
    "    AIMessage(content=\"I've added a rate limiter decorator to the login function.\"),\n",
    "]\n",
    "\n",
    "messages = adapter.convert(langchain_messages)\n",
    "result = await tm.import_trace(\"conv-auth-demo\", messages)\n",
    "print(f\"Imported nodes: {list(result.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-second-heading",
   "metadata": {},
   "source": [
    "## 3. Import a Second Conversation\n",
    "\n",
    "Import another conversation so we have data to search across."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "import-second",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported nodes: ['user_text', 'agent_text', 'resource_file:///src/database.py', 'resource_version_file:///src/database.py', 'resource_version_file:///src/auth.py']\n"
     ]
    }
   ],
   "source": [
    "langchain_messages_2 = [\n",
    "    HumanMessage(content=\"How does the database connection pool work?\"),\n",
    "    AIMessage(\n",
    "        content=\"Let me check the database module.\",\n",
    "        tool_calls=[\n",
    "            {\"id\": \"call_3\", \"name\": \"read_file\", \"args\": {\"file_path\": \"/src/database.py\"}}\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(content=\"pool = create_pool(max_connections=10)\", tool_call_id=\"call_3\"),\n",
    "    AIMessage(content=\"The database uses a connection pool with max 10 connections.\"),\n",
    "    HumanMessage(content=\"Fix the authentication token expiry bug\"),\n",
    "    AIMessage(\n",
    "        content=\"I'll look at the auth module.\",\n",
    "        tool_calls=[\n",
    "            {\"id\": \"call_4\", \"name\": \"read_file\", \"args\": {\"file_path\": \"/src/auth.py\"}}\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\n",
    "        content=\"def create_jwt(user):\\n    return jwt.encode({'exp': time() + 3600}, SECRET)\",\n",
    "        tool_call_id=\"call_4\",\n",
    "    ),\n",
    "    AIMessage(content=\"Found the bug - the token expiry was using time() instead of datetime.utcnow().\"),\n",
    "]\n",
    "\n",
    "messages_2 = adapter.convert(langchain_messages_2)\n",
    "result = await tm.import_trace(\"conv-db-auth-demo\", messages_2)\n",
    "print(f\"Imported nodes: {list(result.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "search-heading",
   "metadata": {},
   "source": [
    "## 4. Search Past Interactions\n",
    "\n",
    "Use `tm.search()` to find relevant past conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(e1827c35, score=0.032, conv=conv-db-auth-demo, text='Fix the authentication token expiry bug', context=yes)\n",
      "\n",
      "Result(e7841365, score=0.016, conv=conv-db-auth-demo, text='How does the database connection pool work?', context=yes)\n",
      "\n",
      "Result(5cdb8835, score=0.016, conv=conv-auth-demo, text='Read the auth.py file and explain the login flow', context=yes)\n",
      "\n",
      "Result(7bee1af5, score=0.016, conv=conv-auth-demo, text='Now add rate limiting to the login endpoint', context=yes)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = await tm.search(\"authentication issues\")\n",
    "\n",
    "for r in results:\n",
    "    print(r)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resource-heading",
   "metadata": {},
   "source": [
    "## 5. Query File History\n",
    "\n",
    "Find all conversations that touched a specific file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "resource-history",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvRef(e1827c35, conv=conv-db-auth-demo, user='Fix the authentication token expiry bug')\n",
      "ConvRef(e7841365, conv=conv-db-auth-demo, user='How does the database connection pool work?')\n",
      "ConvRef(7bee1af5, conv=conv-auth-demo, user='Now add rate limiting to the login endpoint')\n",
      "ConvRef(5cdb8835, conv=conv-auth-demo, user='Read the auth.py file and explain the login flow')\n",
      "ConvRef(5cdb8835, conv=conv-auth-demo, user='Read the auth.py file and explain the login flow')\n"
     ]
    }
   ],
   "source": [
    "refs = await tm.get_conversations_for_resource(\n",
    "    \"file:///src/auth.py\",\n",
    "    config=RetrievalConfig(limit=10, sort_by=\"created_at\", sort_order=\"desc\"),\n",
    ")\n",
    "\n",
    "for ref in refs:\n",
    "    print(ref)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trajectory-heading",
   "metadata": {},
   "source": [
    "## 6. Get Full Trajectory\n",
    "\n",
    "Expand a search result into its full trajectory (user message + all agent responses + tool uses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "trajectory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory(3 steps):\n",
      "  Step(7bee1af5 UserText: 'Now add rate limiting to the login endpoint')\n",
      "  Step(b109d83f AgentText: \"I'll update auth.py to add rate limiting.\" tools=1)\n",
      "  Step(33920720 AgentText: \"I've added a rate limiter decorator to the login function.\")\n"
     ]
    }
   ],
   "source": [
    "results = await tm.search(\"login flow\", config=RetrievalConfig(limit=1))\n",
    "\n",
    "if results:\n",
    "    trajectory = await tm.get_trajectory(results[0].node_id)\n",
    "    print(trajectory)\n",
    "else:\n",
    "    print(\"No results found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reranker-heading",
   "metadata": {},
   "source": [
    "## 7. Reranker Selection\n",
    "\n",
    "Create a second TraceMem instance with a different reranker to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "reranker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with linear reranker: 4\n",
      "  Fix the authentication token expiry bug  (score=1.000)\n",
      "  Now add rate limiting to the login endpoint  (score=0.374)\n",
      "  Read the auth.py file and explain the login flow  (score=0.021)\n",
      "  How does the database connection pool work?  (score=0.000)\n"
     ]
    }
   ],
   "source": [
    "linear_config = TraceMemConfig(\n",
    "    mode=\"global\",\n",
    "    embedding_dimensions=256,\n",
    "    lancedb_path=Path(_tmpdir) / \"lancedb\",\n",
    "    reranker=\"linear\",\n",
    ")\n",
    "\n",
    "async with TraceMem(config=linear_config, embedder=embedder) as tm_linear:\n",
    "    results = await tm_linear.search(\"authentication\")\n",
    "    print(f\"Results with linear reranker: {len(results)}\")\n",
    "    for r in results:\n",
    "        print(f\"  {r.text[:60]}  (score={r.score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-heading",
   "metadata": {},
   "source": [
    "## 8. Cleanup\n",
    "\n",
    "Close the TraceMem connection and remove temp files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cleanup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "await tm.__aexit__(None, None, None)\n",
    "shutil.rmtree(_tmpdir, ignore_errors=True)\n",
    "print(\"Cleaned up\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
